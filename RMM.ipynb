{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b005ce",
   "metadata": {},
   "source": [
    "## Testing RandMatrixMultiply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd3ff8",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e262ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from scipy.sparse import random as sparse_random\n",
    "# from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b98b76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randMatrixMultiply(A: np.matrix, B: np.matrix, c: int, P_k: np.array) -> np.matrix:\n",
    "    \"\"\" This function returns an estimator for the product AB using the random matrix multiplication algorithm\n",
    "\n",
    "    :param A: The first m x n matrix to be multiplied\n",
    "    :param B: The second n x p matrix to be multiplied\n",
    "    :param c: The number of column-row pairs to choose\n",
    "    :param P_k: The probability distribution to choose the probability matrix\n",
    "    :return: The estimator for the product AB\n",
    "    \"\"\"\n",
    "    n = A.shape[1]\n",
    "    C = np.zeros((A.shape[0], c)) # m x c\n",
    "    R = np.zeros((c, B.shape[1])) # c x p\n",
    "    \n",
    "    # Optimal Probability Distribution:\n",
    "    A_col_norms = np.linalg.norm(A, axis=0)  \n",
    "    B_row_norms = np.linalg.norm(B, axis=1)  \n",
    "    P_k = (A_col_norms * B_row_norms) / np.sum(A_col_norms * B_row_norms)\n",
    "    \n",
    "    sorted_pk = np.flip(np.sort(P_k))\n",
    "    \n",
    "    indices = []\n",
    "    for i in range(len(sorted_pk)):\n",
    "        index = list(P_k).index(sorted_pk[i])\n",
    "        indices.append(index)\n",
    "    \n",
    "    for t in range(c): # For t = 0 to c-1\n",
    "        #i_t = np.random.choice(range(n), p=P_k)\n",
    "        i_t=indices[t]\n",
    "        coefficient = 1 / (np.sqrt(c * P_k[i_t]))\n",
    "        C[:, t] = coefficient * A[:, i_t]\n",
    "        R[t, :] = coefficient * B[i_t, :]\n",
    "        \n",
    "    return C @ R\n",
    "\n",
    "def calculate_accuracy(A: np.matrix, B: np.matrix, c: int, P_k: np.array) -> float:\n",
    "    \"\"\" This function calculates the accuracy of randMatrixMultiply compared to normal matrix multiplication\n",
    "\n",
    "    :param A: The first m x n matrix to be multiplied\n",
    "    :param B: The second n x p matrix to be multiplied\n",
    "    :param c: The number of column-row pairs to choose\n",
    "    :param P_k: The probability distribution to choose the probability matrix\n",
    "    :return: The accuracy of the randMatrixMultiply function\n",
    "    \"\"\"\n",
    "    # Compute the product using normal matrix multiplication\n",
    "    AB_exact = A @ B\n",
    "    \n",
    "    # Compute the product using randMatrixMultiply\n",
    "    AB_approx = randMatrixMultiply(A, B, c, P_k)\n",
    "    \n",
    "    # Calculate the Frobenius norm of the difference\n",
    "    difference = AB_exact - AB_approx\n",
    "    frobenius_norm = np.linalg.norm(difference, 'fro')\n",
    "    \n",
    "    # Calculate the Frobenius norm of the exact product\n",
    "    frobenius_norm_exact = np.linalg.norm(AB_exact, 'fro')\n",
    "    \n",
    "    # Calculate the accuracy as 1 - (norm of difference / norm of exact product)\n",
    "    accuracy = 1 - (frobenius_norm / frobenius_norm_exact)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def calculate_loss(A: np.matrix, B: np.matrix, c: int, P_k: np.array) -> float:\n",
    "    \"\"\" This function calculates the loss of randMatrixMultiply compared to normal matrix multiplication\n",
    "\n",
    "    :param A: The first m x n matrix to be multiplied\n",
    "    :param B: The second n x p matrix to be multiplied\n",
    "    :param c: The number of column-row pairs to choose\n",
    "    :param P_k: The probability distribution to choose the probability matrix\n",
    "    :return: The loss of the randMatrixMultiply function\n",
    "    \"\"\"\n",
    "\n",
    "    AB_exact = A @ B\n",
    "    AB_approx = randMatrixMultiply(A, B, c, P_k)\n",
    "    # Calculate the Frobenius norm of the difference\n",
    "    difference = AB_exact - AB_approx\n",
    "    frobenius_norm = np.linalg.norm(difference, 'fro')\n",
    "    \n",
    "    return frobenius_norm/np.linalg.norm(AB_approx, 'fro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882a9d4b",
   "metadata": {},
   "source": [
    "### Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba50341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dimensions of the matrices\n",
    "m = 10000\n",
    "n = 1000\n",
    "p = 500\n",
    "\n",
    "# # Create the matrices A and B\n",
    "A = np.random.poisson(size=(m, n))\n",
    "B = np.random.poisson(size=(n, p))\n",
    "\n",
    "# Choose the number of column-row pairs to choose\n",
    "c = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a2cad",
   "metadata": {},
   "source": [
    "### Testing RandMatrixMultiply with uniform probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec0e6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05296888712897044\n"
     ]
    }
   ],
   "source": [
    "# for c in range(1,99):\n",
    "loss = calculate_loss(A, B, 500, [])\n",
    "    \n",
    "print(\"Loss: \"+str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "729163b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcalculate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP_k\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(losses)))\n\u001b[1;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLosses of Multiple trials of RMM algorithm (optimal prob dist)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 73\u001b[0m, in \u001b[0;36mcalculate_loss\u001b[0;34m(A, B, c, P_k)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" This function calculates the loss of randMatrixMultiply compared to normal matrix multiplication\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m:param A: The first m x n matrix to be multiplied\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m:return: The loss of the randMatrixMultiply function\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     72\u001b[0m AB_exact \u001b[38;5;241m=\u001b[39m A \u001b[38;5;241m@\u001b[39m B\n\u001b[0;32m---> 73\u001b[0m AB_approx \u001b[38;5;241m=\u001b[39m \u001b[43mrandMatrixMultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Calculate the Frobenius norm of the difference\u001b[39;00m\n\u001b[1;32m     75\u001b[0m difference \u001b[38;5;241m=\u001b[39m AB_exact \u001b[38;5;241m-\u001b[39m AB_approx\n",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m, in \u001b[0;36mrandMatrixMultiply\u001b[0;34m(A, B, c, P_k)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandMatrixMultiply\u001b[39m(A: np\u001b[38;5;241m.\u001b[39mmatrix, B: np\u001b[38;5;241m.\u001b[39mmatrix, c: \u001b[38;5;28mint\u001b[39m, P_k: np\u001b[38;5;241m.\u001b[39marray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mmatrix:\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" This function returns an estimator for the product AB using the random matrix multiplication algorithm\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    :param A: The first m x n matrix to be multiplied\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    :return: The estimator for the product AB\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     n \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Optimal Probability Distribution:\n",
    "A_col_norms = np.linalg.norm(A, axis=0)  \n",
    "B_row_norms = np.linalg.norm(B, axis=1)  \n",
    "P_k = (A_col_norms * B_row_norms) / np.sum(A_col_norms * B_row_norms)\n",
    "\n",
    "losses = []\n",
    "for i in range(1000):\n",
    "    losses.append(calculate_loss(A, B, c, P_k))\n",
    "\n",
    "print(\"Mean: \"+str(np.mean(losses)))\n",
    "\n",
    "plt.title('Losses of Multiple trials of RMM algorithm (optimal prob dist)')\n",
    "plt.xlabel('Losses')\n",
    "plt.ylabel('Number of trials')\n",
    "plt.hist(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0198b0ca",
   "metadata": {},
   "source": [
    "### Effect of varying number of sampled row/column pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "#Effect of varying c\n",
    "\n",
    "A_col_norms = np.linalg.norm(A, axis=0)  \n",
    "B_row_norms = np.linalg.norm(B, axis=1)  \n",
    "P_k = (A_col_norms * B_row_norms) / np.sum(A_col_norms * B_row_norms)\n",
    "\n",
    "averageaccs=[]\n",
    "for c in tqdm(range(5,100)):\n",
    "    losses = []\n",
    "    for i in range(10):\n",
    "        losses.append(calculate_loss(A, B, c, P_k))\n",
    "    averageaccs.append(np.mean(losses))\n",
    "\n",
    "plt.title('Average Loss for different c')\n",
    "plt.xlabel('c')\n",
    "plt.ylabel('average loss')\n",
    "plt.plot(range(5,100), averageaccs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0080ff30-98d6-4894-be43-620796b81f61",
   "metadata": {},
   "source": [
    "# RandNLA Approaches for Regression Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b066512e-44a2-400c-bfd3-02b337dbf990",
   "metadata": {},
   "source": [
    "### 5.1 The Randomized Hadamard Transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6a3ecf-9813-4ae9-954a-b02d73490ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import hadamard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "51b758da-9f54-4963-bcc7-1001cbb50dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add r to be linear or non-linear\n",
    "# TODO: light analysis on run-time as we change dimension, epsilon. \n",
    "# graph of size vs run-time. accuracies vs epsilon\n",
    "# setting r w/ log vs linear, how that affects accuracy\n",
    "\n",
    "# 1. size vs run-time\n",
    "# 2. accuracy vs epsilon\n",
    "# 3. how r is set (log vs linear) vs accuracy & run-time\n",
    "\n",
    "def randLeastSquares(A: np.matrix, b: np.array, epsilon: float):\n",
    "    \"\"\"\n",
    "    Solves the least squares problem using a randLeastSquares algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    A (np.matrix): The input matrix of shape (n, d).\n",
    "    b (np.array): The target vector of shape (n).\n",
    "    epsilon (float): The error tolerance for the approximation.\n",
    "\n",
    "    Returns:\n",
    "    np.array: The solution vector of shape (d).\n",
    "    \"\"\"\n",
    "    # assumes A is full rank and n power of 2\n",
    "    n, d = A.shape\n",
    "    \n",
    "    # Ensure n is a power of 2\n",
    "    # TODO: pad with 0s to get to the next power of 2\n",
    "    if not (n > 0 and ((n & (n - 1)) == 0)):\n",
    "        raise ValueError(\"n must be a positive integer, and n must be a power of 2\")\n",
    "\n",
    "    # n has to be less than e^d, bc yeah. \n",
    "    r = max(48**2 * d * np.log(40*n*d) * np.log(100**2 * d * np.log(40*n*d)), (40 * d * np.log(40 * n * d)) / epsilon)\n",
    "    r = int(np.ceil(r))\n",
    "    # r = 2 * n\n",
    "    # linear rather than log cuz it makes the values a lot more smaller, rnu time was too damn long earlier!\n",
    "    r = max(48**2 * d, (40 * d )/ epsilon)\n",
    "    r = int(np.ceil(r))\n",
    "    \n",
    "    # print(\"r\", r)\n",
    "    # r = 1000\n",
    "\n",
    "    # Creation of the samping-and-rescaling matrix S\n",
    "    S = np.zeros((r, n))\n",
    "    for t in range(r):\n",
    "        i_t = np.random.choice(range(n))\n",
    "        # for step 3, what is i? \n",
    "        S[t, i_t] = np.sqrt(n/r)\n",
    "    H = hadamard(n) / np.sqrt(n)\n",
    "    D_diags = np.random.choice([-1, 1], size=n)\n",
    "    D = np.diag(D_diags)\n",
    "\n",
    "    # Compute HDA and HDb\n",
    "    HDA = H @ D @ A\n",
    "    HDb = H @ D @ b\n",
    "\n",
    "    # Generate a random sampling matrix S\n",
    "    # S = np.random.randn(r, m)\n",
    "\n",
    "    # Compute the solution vector x_opt\n",
    "    x_opt = np.linalg.pinv(S @ HDA) @ (S @ HDb)\n",
    "    return x_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "691b3549-5a91-4585-8d12-60341ae8c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8b9d42ab-390f-4f8c-899e-c2531817821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:04<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error over 5 tests: 0.019331471342575336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def relative_err(x_opt, x_true):\n",
    "    return np.linalg.norm(x_opt - x_true) / np.linalg.norm(x_opt)\n",
    "\n",
    "# Parameters\n",
    "num_tests = 5\n",
    "matrix_size = (2**5, 8)\n",
    "epsilon = 0.01\n",
    "\n",
    "# Run multiple tests\n",
    "err = []\n",
    "A = np.random.randn(*matrix_size)\n",
    "b = np.random.randn(matrix_size[0])\n",
    "x_true = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "for _ in tqdm(range(num_tests)):\n",
    "    \n",
    "    \n",
    "    x_opt = randLeastSquares(A, b, epsilon)\n",
    "    # print(x_opt)\n",
    "    # print(x_true)\n",
    "    \n",
    "    acc = relative_err(x_opt, x_true)\n",
    "    err.append(acc)\n",
    "\n",
    "# Compute average accuracy\n",
    "average_err = np.mean(err)\n",
    "print(\"Average error over {} tests: {}\".format(num_tests, average_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2909c89d-5fe2-4b68-9e55-3d63457b1198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3cef6b-e810-4d64-9858-1255991d3712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
